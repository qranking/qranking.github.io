<html>
	<head><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110075493-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-110075493-1');
</script>
<!-- Google AdSense -->
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6168511236629369",
    enable_page_level_ads: true
  });
</script>

		<meta charset="UTF-8" />
		<title>Qiita Ranking (icoxfog417)</title>
		<link rel="stylesheet" type="text/css" href="../qranking.css">
	</head>
	<body>
<div class="headerContainer">
<h1>Qiitaいいね数ランキング (icoxfog417 さんの投稿分)</h1>
</div><!--class="headerContainer"-->
<p><a href="#" onclick="javascript:window.history.back(-1);return false;">[戻る]</a></p>
<p><i><img width="16" height="16" src="../thumb-up-120px.png" /></i>が同じ値の場合は投稿日時の新しいものが上位としています。</p>
<p><i><img width="16" height="16" src="../thumb-up-120px.png" /></i>がついていない記事は表示していません。</p>
<table border="1">
<tr>
	<td rowspan="3"><center>icoxfog417さんの<br />1位</center></td>
	<td colspan="4">
		<kbd><i><img alt="いいね" width="16" height="16" src="../thumb-up-120px.png" /></i>398</kbd>
		<a target="_blank" href="https://qiita.com/icoxfog417/items/d06651db10e27220c819">大自然言語時代のための、文章要約</a>
	</td>
</tr>
<tr>
	<td style="width:100px;"><center>投稿日時</center></td>
	<td style="width:200px;"><center>投稿者</center></td>
	<td style="width:150px;"><center>タグ</center></td>
	<td style="width:350px;"><center>本文</center></td>
</tr>
<tr>
	<td style="width:100px;">
		<!--投稿日時--><center>2017-10-18 15:22:25</center>
	</td>
	<td style="width:200px;">
		@icoxfog417<br><img width="80" height="80" src="https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516">
	</td>
	<td style="width:150px;">
		<!--タグ-->
		<center><b>[Python]</b> <b>[自然言語処理]</b> <b>[機械学習]</b> <b>[MachineLearning]</b> </center>
	</td>
	<td style="width:350px;">
		<!--本文-->
		<div style="width:350px;height:150px;overflow-x:hidden;overflow-y:scroll;"><p>さまざまなニュースアプリ、ブログ、SNSと近年テキストの情報はますます増えています。日々たくさんの情報が配信されるため、Twitterやまとめサイトを見ていたら数時間たっていた・・・なんてこともよくあると思います。世はまさに大自然言語時代。</p>

<p><a href="https://camo.qiitausercontent.com/890215ed7d661fea6ffd4facea8a987820a6caa6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f37643965306231372d646530642d323431632d366439652d6536313265616634333066302e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/890215ed7d661fea6ffd4facea8a987820a6caa6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f37643965306231372d646530642d323431632d366439652d6536313265616634333066302e706e67" alt="growth_of_data.PNG" width="500" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/7d9e0b17-de0d-241c-6d9e-e612eaf430f0.png"></a><br>
<em>from <a href="https://www.signiant.com/articles/file-transfer/the-historical-growth-of-data-why-we-need-a-faster-transfer-solution-for-large-data-sets/" rel="nofollow noopener" target="_blank">THE HISTORICAL GROWTH OF DATA: WHY WE NEED A FASTER TRANSFER SOLUTION FOR LARGE DATA SETS</a><br>
テキスト、音声、画像、動画といった非構造データの増加を示したグラフ</em></p>

<p>そこで注目される技術が、「要約」です。膨大な情報を要点をまとめた短い文章にすることができれば、単純に時間の節約になるだけでなく、多様な視点から書かれた情報を並べて吟味することもできます。<br>
本文書は、この文書要約(Text Summarization)についてその概観を示すことを目的として書かれています。具体的には、以下の順に沿って解説をしていきます。</p>

<ol>
<li>要約というタスクの種類</li>
<li>要約を作成する手法</li>
<li>良い要約の評価</li>
<li>要約の作成に使えるツール</li>
<li>要約を試すためのデータセット</li>
</ol>

<h1>
<span id="1-要約というタスクの種類" class="fragment"></span><a href="#1-%E8%A6%81%E7%B4%84%E3%81%A8%E3%81%84%E3%81%86%E3%82%BF%E3%82%B9%E3%82%AF%E3%81%AE%E7%A8%AE%E9%A1%9E"><i class="fa fa-link"></i></a>1. 要約というタスクの種類</h1>

<p>単純に「要約」といっても、いろいろな種類があるためまずはそれらを整理します。今後要約に取り組みたいと思ったときに、どんな「要約」に挑戦しようとしているのかをはっきりさせる足掛かりにしていただければと思います。</p>

<p>要約というタスクを整理する観点としては、3つの観点があります。</p>

<p><a href="https://camo.qiitausercontent.com/5cfb665efb466e7d67cc6529db68fee691aee663/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f30653635343863642d373231312d346466612d616130372d6330663465396561343931322e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/5cfb665efb466e7d67cc6529db68fee691aee663/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f30653635343863642d373231312d346466612d616130372d6330663465396561343931322e706e67" alt="summarization_task.PNG" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/0e6548cd-7211-4dfa-aa07-c0f4e9ea4912.png"></a></p>

<ol>
<li>要約のインプットとなる文書</li>
<li>要約作成に対する意思入れ</li>
<li>作成される要約の内容</li>
</ol>

<p>第一に、要約するのは単一の文書なのか、複数の文書なのかといった観点があります。単一の場合は<strong>Single document summarization</strong>、複数の場合は<strong>Multi-document summarization</strong>と呼ばれます。</p>

<p>第二に、要約に際して何らかの指示を与えるかという観点があります。何も指示をせず単純に要約を作成する処理を<strong>Generic summarization</strong>と呼びます。これに対して、何らかのトピックやキーワードを指定してそれを中心とした要約を作成させることを<strong>Query focused summarization</strong>と呼びます。この特殊なケースとして、文章の更新前後の差分に着目する<strong>Update summarization</strong>があります。これは例えば、メールの要約を行う際に前回のメールとの差分に特に注目して要約を行うといったようなタスクになります。<br>
実用的な側面としては、指示を与えない単純な要約(Generic summarization)は意味がないという議論もあります(<a href="https://www.cl.cam.ac.uk/archive/ksj21/ksjdigipapers/summbook99.pdf" rel="nofollow noopener" target="_blank">Automatic summarizing: factors and directions</a>)。これは個人的にはかなり共感する意見です(実際作成してみた要約を見ると特にそう感じます)。</p>

<p>最後に、作成する要約の内容、スタイルについての観点があります。内容については、例えば書籍や映画を紹介するために要約する場合、ネタバレしてしまうと困るでしょう。その場合内容全体まではわからないように要約を作成することになりますが、こうした要約を<strong>Indicative summary</strong>と呼びます。これとは逆に、すべての内容をもとに作成する要約を<strong>Informative summary</strong>と呼びます。<br>
要約のスタイルは、長さや形式といった観点です。特に一行でまとめるような要約を<strong>Headline summary</strong>と呼びます。また文ではなく、単語だけを抽出するようなスタイルを<strong>Keyword summary</strong>と呼びます。</p>

<p>要約に取り組む際は、これら3つの観点を元にどういったタスクかを定義することで、先行研究の調査が行いやすくなります。</p>

<h1>
<span id="2-要約を作成する手法" class="fragment"></span><a href="#2-%E8%A6%81%E7%B4%84%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B%E6%89%8B%E6%B3%95"><i class="fa fa-link"></i></a>2. 要約を作成する手法</h1>

<p>要約を作成するには、主に抽出型(Extractive)と抽象型(Abstractive)の2つのアプローチがあります。本節では、各アプローチの概要とその代表的なアルゴリズムについて解説を行います。</p>

<h2>
<span id="21-抽出型extractive" class="fragment"></span><a href="#21-%E6%8A%BD%E5%87%BA%E5%9E%8Bextractive"><i class="fa fa-link"></i></a>2.1 抽出型(Extractive)</h2>

<p>抽出型は、要約対象の文章の中から重要と思われる文を抽出して要約を作成するというアプローチです。そのメリットとデメリットは、以下のようになります。</p>

<ul>
<li>メリット： 元の文章中にある文を選択して要約を作成するため、まったく内容がつかめない要約になる可能性が低く、文法的におかしな要約になることもない</li>
<li>デメリット： 文中にない単語を利用することはできないため、抽象化や言い換え、読みやすくするための接続詞の使用などができない。このため、作成された要約は粗雑な印象になる。</li>
</ul>

<p>続いて、抽出型の代表的な手法をいくつか紹介します。</p>

<h3>
<span id="211-graph-base-methods" class="fragment"></span><a href="#211-graph-base-methods"><i class="fa fa-link"></i></a>2.1.1 Graph Base Methods</h3>

<p>グラフベースの手法は、文章をグラフ構造で表現し各ノード(=文や単語)の関係性を元に要約を作成するという手法です。代表的なアルゴリズムとしては、<a href="https://web.eecs.umich.edu/%7Emihalcea/papers/mihalcea.emnlp04.pdf" rel="nofollow noopener" target="_blank">TextRank</a>があります。TextRankは、Google検索の基礎となっている<a href="https://en.wikipedia.org/wiki/PageRank" rel="nofollow noopener" target="_blank">PageRank</a>という手法を文章に応用した手法です。PageRankの基本的な考えは、リンクされているページは良いページで、さらに多くリンクされているページ(=人気のページ)からのリンクは高く評価されるというものです。この評価は、ページに対するユーザーの流入量と等価になります(多くのページからリンクが張られていれば流入しやすく、人気のページからの流入は通常のページからの流入より大きい)。ページ間のリンクは行列で表現することができ、各ページにおけるリンクの総数で割ることでこの行列はユーザーがそのページからリンクが張られた別のページに遷移する確率の行列になります(下図$M$)。これを利用し、ユーザーが各ページに滞在する確率(下図$P$)=ページの評価を求めることがPageRankの目的です。</p>

<p><a href="https://camo.qiitausercontent.com/62485ee6e3e9cbe420acb6d133bb29d4ec8c9195/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f62336439636339632d373862322d616532342d386339362d3864663464626539303661642e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/62485ee6e3e9cbe420acb6d133bb29d4ec8c9195/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f62336439636339632d373862322d616532342d386339362d3864663464626539303661642e706e67" alt="page_rank_2.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/b3d9cc9c-78b2-ae24-8c96-8df4dbe906ad.png"></a></p>

<p>$P$を求めるには、固有値問題を解く方法とページ遷移の試行を繰り返す方法の2つのアプローチがあります。何れも、多くの回数ページ遷移を繰り返していけば、最終的にページの滞在確率は安定する($MP=P$が成立する)という前提に基づいています。固有値問題を解く方法はこれを実現する$P$を直接求めることができますが、行列のサイズが大きくなると解くのにすごく時間がかかります。試行ベースの方は、一発では解けませんがページ数が多い場合でも$P$を求めることができます。<br>
PageRankの説明が長くなりましたが、TextRankはこれを文章に応用した手法になります。TextRankのポイントは以下の2点です。</p>

<ul>
<li>何をNodeとするか：単語、文etc..</li>
<li>何をEdgeとするか：単語/文の類似度、参照関係etc</li>
</ul>

<p>この定義が決まれば、あとはPageRankと同じ手法で解くことができます。なお、<a href="https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html" rel="nofollow noopener" target="_blank">LexRank</a>はNodeに文、Edge/Weightに類似度を使用した手法になります。</p>

<p><a href="https://camo.qiitausercontent.com/5deebd245f373d0df4c492a6d6c3e6e19a694a7e/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f37336638653132652d633138362d396430312d313435312d3962326237656638363538362e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/5deebd245f373d0df4c492a6d6c3e6e19a694a7e/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f37336638653132652d633138362d396430312d313435312d3962326237656638363538362e706e67" alt="lexrank.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/73f8e12e-c186-9d01-1451-9b2b7ef86586.png"></a></p>

<h3>
<span id="212-feature-base-methods" class="fragment"></span><a href="#212-feature-base-methods"><i class="fa fa-link"></i></a>2.1.2 Feature Base Methods</h3>

<p>文の特徴を定義して、その特徴による重みづけ(スコアリング)を行うことで文選択を行うのがFeature Baseの手法です。例えば、以下の論文がFeature Baseの手法として挙げられます。</p>

<p><a href="http://oldwww.iiit.ac.in/cgi-bin/techreports/display_detail.cgi?id=IIIT/TR/2008/97" rel="nofollow noopener" target="_blank">Sentence Extraction Based Single Document Summarization</a></p>

<p>この論文では、文のスコアリングをした後に、文の選択を行っています。文のスコアリングには、以下の特徴が使用されています。</p>

<ul>
<li>文章における、文の位置</li>
<li>文に動詞が含まれるか否か</li>
<li>文の長さ</li>
<li>単語の出現頻度</li>
<li>単語の固有表現</li>
<li>単語に適用されているフォントスタイル</li>
</ul>

<p>・・・などです。これらの特徴は、以下の計算式で一つのスコアにまとめられます。</p>

<p><a href="https://camo.qiitausercontent.com/654d27b0835799577f4539d5553a31d6481f28d5/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f62613366373530622d663465362d623335632d373966622d3537653166616134323830662e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/654d27b0835799577f4539d5553a31d6481f28d5/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f62613366373530622d663465362d623335632d373966622d3537653166616134323830662e706e67" alt="feature_base_score.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/ba3f750b-f4e6-b35c-79fb-57e1faa4280f.png"></a></p>

<p>単語ベースの特徴を掛け合わせて$Score(l, w)$を算出し、文中に含まれる各単語のスコアを合計しています。なお、前の文章への参照を考慮するために、<em>No.of coreferences</em>を使用しています。これは単純に文の前半に含まれる代名詞の数で、代名詞の数分だけ一つ前の文章の平均スコア($Score$を$length$で割った$SPW$)をかけています。<br>
特徴ベースの歴史は古く、古典的な<a href="http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf" rel="nofollow noopener" target="_blank">Luhn’s Algorithm</a>では、単語の出現頻度から「重要度」を算出し、それが文を区切ったバケットにどれだけ含まれるかでスコアリングを行っています。</p>

<p>続いて、文の選択には算出したスコアだけでなく「選択済み」の文に含まれる単語との一致率が考慮されています。これは、既に選択した文との情報の重複を避けるための工夫です。さらに、そのあと文のつながりを自然にするために疑問形の削除や特定接続詞の削除などを行っています(Refinement)。</p>

<p>なお、文選択のプロセスはFeature Baseだけでなく抽出型全体において重要なプロセスです。というのも、単純にスコアの高い順から文を選択していくと情報の重複などが起こってしまうためです。文選択後のブラッシュアップであるRefinementについても同様のことが言えます。</p>

<h3>
<span id="213-topic-base-methods" class="fragment"></span><a href="#213-topic-base-methods"><i class="fa fa-link"></i></a>2.1.3 Topic Base Methods</h3>

<p>Topic Baseの手法は、文章のトピックを算出し、そのトピックに沿った文を選択するという手法です。重要なトピックに近い文を選択する、各トピックの代表文を選ぶ、などです。Topic Baseの手法については、以下の論文によくまとめられています。</p>

<p><a href="https://www.researchgate.net/publication/220195824_Text_summarization_using_Latent_Semantic_Analysis" rel="nofollow noopener" target="_blank">Text summarization using Latent Semantic Analysis</a></p>

<p>Topic Baseの手法ではLSA(Latent Semantic Analysis)という手法が良く用いられます。これは、縦に文、横に単語をとった文章行列を特異値分解(Singular Value Decomposition=SVD)にかけて、その固有ベクトル(=トピック)を算出するという手法です。以下の図は、SVDを実行して得られた2つのトピック成分上に各文をプロットした図(左)と、各トピックごとに最も高い値を持つ文を選択している図になります(右)。</p>

<p><a href="https://camo.qiitausercontent.com/c5841eb1a392e86bcdade7b69cbdfa173fb413f4/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f36663334313233652d336232382d376430652d343137302d3135303263343133323461382e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/c5841eb1a392e86bcdade7b69cbdfa173fb413f4/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f36663334313233652d336232382d376430652d343137302d3135303263343133323461382e706e67" alt="topic_base.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/6f34123e-3b28-7d0e-4170-1502c41324a8.png"></a></p>

<p>特異値分解の結果得られた固有ベクトルや固有値をどのように使って文のスコアを算出するのか、またどのように文を選択していくのか、という点で様々なバリエーションがあります。</p>

<h2>
<span id="22-抽象型abstractive" class="fragment"></span><a href="#22-%E6%8A%BD%E8%B1%A1%E5%9E%8Babstractive"><i class="fa fa-link"></i></a>2.2 抽象型(Abstractive)</h2>

<p>抽象型は、人が要約を作成するときのように、文章の意味を汲み取ったうえで(=抽象化した上で)適切な要約を作成する手法です。そのメリットとデメリットは、以下のようになります。</p>

<ul>
<li>メリット： 元の文中にはない単語を自由に使って要約を作成できるため、より自然な要約を作成できる。また、要約の長さに対する自由度が大きい。</li>
<li>デメリット： 文法的に違和感がなく、また前後の文脈で不整合が生じないような自然な文を生成することが難しい。</li>
</ul>

<p>抽象型の代表的な手法としては、Encoder-Decoderモデルがあります。</p>

<h3>
<span id="221-encoder-decoder-model" class="fragment"></span><a href="#221-encoder-decoder-model"><i class="fa fa-link"></i></a>2.2.1 Encoder-Decoder Model</h3>

<p>Encoder-Decoderモデルは、Encoderで文を潜在表現に圧縮し、Decoderは圧縮された表現から文を生成する、というモデルです。翻訳のタスクでよく使用されるモデルで、翻訳元の文をEncoderで圧縮し、翻訳先の文にDecodeするといった形で利用されています。</p>

<p><a href="https://camo.qiitausercontent.com/3e4315d391094491b8534802c5a98df344f9ae16/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f35316331666565622d666463322d626334322d616564632d3462613532666134633131662e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/3e4315d391094491b8534802c5a98df344f9ae16/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f35316331666565622d666463322d626334322d616564632d3462613532666134633131662e706e67" alt="encoder-decoder.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/51c1feeb-fdc2-bc42-aedc-4ba52fa4c11f.png"></a><br>
<a href="https://www.slideshare.net/YusukeOda1/encoderdecoder-tis" rel="nofollow noopener" target="_blank">Encoder-decoder 翻訳 (TISハンズオン資料)</a></p>

<p>要約に適用する場合、文章をEncoder入れていきDecoderから要約を生成させる形になります。文章から直接要約を生成するという形になるため、End-to-Endのモデルともいわれます。TensorFlowには、この形式で要約を作成するモデルが組み込まれています。</p>

<p><a href="https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html" rel="nofollow noopener" target="_blank">Text summarization with TensorFlow</a></p>

<p>なお、抽出型と抽象型のいい所どりをする研究も近年は進められています。以下の研究は、抽出と生成をスイッチする確率p_genを算出しながら要約を作成するとうアイデアです。</p>

<p><a href="https://arxiv.org/abs/1704.04368" rel="nofollow noopener" target="_blank">Get To The Point: Summarization with Pointer-Generator Networks</a></p>

<p><a href="https://camo.qiitausercontent.com/22c73a774131f4f6063ea51fe657b9de42055928/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f61343533373737622d376337322d666561342d623335302d6666653830326364636162312e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/22c73a774131f4f6063ea51fe657b9de42055928/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f61343533373737622d376337322d666561342d623335302d6666653830326364636162312e706e67" alt="pointer-generator-network.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/a453777b-7c72-fea4-b350-ffe802cdcab1.png"></a></p>

<h1>
<span id="3-良い要約の評価" class="fragment"></span><a href="#3-%E8%89%AF%E3%81%84%E8%A6%81%E7%B4%84%E3%81%AE%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>3. 良い要約の評価</h1>

<p>要約を評価する観点としては、通常の機械学習と同様適合率(Precision)と再現率(Recall)の観点があります。</p>

<h2>
<span id="31-rouge-nカバー率の評価" class="fragment"></span><a href="#31-rouge-n%E3%82%AB%E3%83%90%E3%83%BC%E7%8E%87%E3%81%AE%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>3.1 <a href="https://en.wikipedia.org/wiki/ROUGE_(metric)" rel="nofollow noopener" target="_blank">ROUGE-N</a>　カバー率の評価</h2>

<p>ROUGE-NのNはN-gramのNで、生成した要約と人間が作成した要約がN-gram単位でどれだけ一致しているかを計測した指標です。ROUGE-1なら単語単位、ROUGE-2ならbi-gram単位の一致になります。例えば、"いちご ばなな"と"ばなな いちご"は、ROUGE-1単位(単語単位)では一致しますが、ROUGE-2、つまりbi-gramなら"いちご ばなな"が一単位になるため一致はしなくなります。これは即ち正解の要約文中にあるN-gramの組み合わせがどれだけ生成した要約に出てくるかを表しており、乱暴に言えば要約文をすごく長くすればそれだけROUGEスコアは高くなる傾向があります。そうした意味で、ROUGEによる評価はRecall的といえます。もちろん、これだけでは「実際の要約にはない」単語=ミスが評価されません。そこで出てくるのが、次のBLEUスコアです。</p>

<h2>
<span id="32-bleu--一致率の評価" class="fragment"></span><a href="#32-bleu--%E4%B8%80%E8%87%B4%E7%8E%87%E3%81%AE%E8%A9%95%E4%BE%A1"><i class="fa fa-link"></i></a>3.2 <a href="http://www.aclweb.org/anthology/P02-1040.pdf" rel="nofollow noopener" target="_blank">BLEU</a>  一致率の評価</h2>

<p>BLEUは、生成した要約のN-gram中のどれだけが実際の要約に登場するかで評価されます(なお、この場合長い文は短い文に比べてN-gram数が大きくなり不利になるため、調整が行われています)。BLEUは分母に生成した要約のN-gram数が来るため、乱発すればそれだけ一致する率は下がることになります。このため、Precision的な評価が可能になります。なお、BLEUは翻訳のタスクでよく使用されています。</p>

<p>実際には、評価ではROUGEが使われることが多いです。というのも、たいていの場合要約の長さには制限があり、「長々生成してスコアを稼ぐ」という戦略自体が利用できないためです。</p>

<h1>
<span id="4要約の作成に使えるツールデータセット" class="fragment"></span><a href="#4%E8%A6%81%E7%B4%84%E3%81%AE%E4%BD%9C%E6%88%90%E3%81%AB%E4%BD%BF%E3%81%88%E3%82%8B%E3%83%84%E3%83%BC%E3%83%AB%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88"><i class="fa fa-link"></i></a>4.要約の作成に使えるツール・データセット</h1>

<p>要約を作成してみたいという熱が高まったに違いないと思うので、最後に実際に要約を作成できるツールとデータセットを紹介します。</p>

<h2>
<span id="41-ツール" class="fragment"></span><a href="#41-%E3%83%84%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>4.1 ツール</h2>

<p>これまで紹介した、抽出型/抽象型の要約の手法ごとに紹介します。</p>

<p>抽出型(Extractive)</p>

<ul>
<li>Graph Base

<ul>
<li><a href="https://radimrehurek.com/gensim/summarization/summariser.html" rel="nofollow noopener" target="_blank">gensim</a></li>
<li><a href="https://github.com/ceteri/pytextrank" rel="nofollow noopener" target="_blank">pytextrank</a></li>
</ul>
</li>
<li>Feature Base

<ul>
<li>
<a href="https://github.com/MojoJolo/textteaser" rel="nofollow noopener" target="_blank">TextTeaser</a> </li>
<li><a href="https://github.com/xiaoxu193/PyTeaser" rel="nofollow noopener" target="_blank">PyTeaser</a></li>
</ul>
</li>
<li>Topic Base

<ul>
<li><a href="https://radimrehurek.com/gensim/models/lsimodel.html" rel="nofollow noopener" target="_blank">gensim models.lsimodel</a></li>
</ul>
</li>
</ul>

<p><a href="https://github.com/miso-belica/sumy" rel="nofollow noopener" target="_blank">sumy</a>は、抽出型の手法を広くカバーするソフトウェアになっています。</p>

<p>抽象型(Abstractive)</p>

<ul>
<li><a href="https://github.com/tensorflow/models/tree/master/research/textsum" rel="nofollow noopener" target="_blank">TensorFlow textsum</a></li>
</ul>

<h2>
<span id="42-データセット" class="fragment"></span><a href="#42-%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88"><i class="fa fa-link"></i></a>4.2 データセット</h2>

<p>要約を行うためのデータセットとしては、以下のデータセットがあります。</p>

<ul>
<li>
<a href="http://www.cis.upenn.edu/%7Enlp/corpora/sumrepo.html" rel="nofollow noopener" target="_blank">DUC 2004</a>

<ul>
<li>最もメジャーですが、ダウンロードをするのに署名してメール送信しないといけないなどハードルが高いです</li>
</ul>
</li>
<li>
<a href="https://catalog.ldc.upenn.edu/LDC2012T21" rel="nofollow noopener" target="_blank">Annotated English Gigaword</a>

<ul>
<li>こちらは有料のデータセットになります</li>
</ul>
</li>
<li><a href="http://kavita-ganesan.com/opinosis-opinion-dataset" rel="nofollow noopener" target="_blank">Opinosis Dataset - Topic related review sentences</a></li>
<li><a href="http://www.l3s.de/%7Egtran/timeline/" rel="nofollow noopener" target="_blank">17 Timelines</a></li>
<li><a href="http://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports" rel="nofollow noopener" target="_blank">Legal Case Reports Data Set</a></li>
</ul>

<h1>
<span id="x参考文献" class="fragment"></span><a href="#x%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><i class="fa fa-link"></i></a>X.参考文献</h1>

<p>Papers</p>

<ul>
<li><a href="https://www.cis.upenn.edu/%7Enenkova/1500000015-Nenkova.pdf" rel="nofollow noopener" target="_blank">Automatic summarization</a></li>
<li><a href="https://www.cl.cam.ac.uk/archive/ksj21/ksjdigipapers/summbook99.pdf" rel="nofollow noopener" target="_blank">Automatic summarizing: factors and directions</a></li>
<li><a href="https://web.eecs.umich.edu/%7Emihalcea/papers/mihalcea.emnlp04.pdf" rel="nofollow noopener" target="_blank">TextRank: Bringing Order into Texts</a></li>
<li><a href="https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html" rel="nofollow noopener" target="_blank">LexRank: Graph-based Lexical Centrality as Salience in Text Summarization</a></li>
<li><a href="http://oldwww.iiit.ac.in/cgi-bin/techreports/display_detail.cgi?id=IIIT/TR/2008/97" rel="nofollow noopener" target="_blank">Sentence Extraction Based Single Document Summarization</a></li>
<li><a href="http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf" rel="nofollow noopener" target="_blank">Luhn’s Algorithm</a></li>
<li><a href="https://www.researchgate.net/publication/220195824_Text_summarization_using_Latent_Semantic_Analysis" rel="nofollow noopener" target="_blank">Text summarization using Latent Semantic Analysis</a></li>
<li><a href="https://arxiv.org/abs/1704.04368" rel="nofollow noopener" target="_blank">Get To The Point: Summarization with Pointer-Generator Networks</a></li>
</ul>

<p>Blog/Wikis</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/PageRank" rel="nofollow noopener" target="_blank">PageRank</a></li>
<li><a href="https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/" rel="nofollow noopener" target="_blank">Text Summarization in Python: Extractive vs. Abstractive techniques revisited</a></li>
<li><a href="https://www.slideshare.net/YusukeOda1/encoderdecoder-tis" rel="nofollow noopener" target="_blank">Encoder-decoder 翻訳 (TISハンズオン資料)</a></li>
<li><a href="https://en.wikipedia.org/wiki/ROUGE_(metric)" rel="nofollow noopener" target="_blank">ROUGE-N</a></li>
<li><a href="http://www.aclweb.org/anthology/P02-1040.pdf" rel="nofollow noopener" target="_blank">BLEU</a></li>
<li><a href="http://www2.nict.go.jp/astrec-att/member/mutiyama/corpmt/4.pdf" rel="nofollow noopener" target="_blank">4. 自動評価尺度 BLEU</a></li>
</ul>
</div>
	</td>
</tr>
</table>
<br />
<table border="1">
<tr>
	<td rowspan="3"><center>icoxfog417さんの<br />2位</center></td>
	<td colspan="4">
		<kbd><i><img alt="いいね" width="16" height="16" src="../thumb-up-120px.png" /></i>30</kbd>
		<a target="_blank" href="https://qiita.com/icoxfog417/items/429f3dddede4786234a4">Pythonプログラムのパフォーマンスを解析し、可視化する</a>
	</td>
</tr>
<tr>
	<td style="width:100px;"><center>投稿日時</center></td>
	<td style="width:200px;"><center>投稿者</center></td>
	<td style="width:150px;"><center>タグ</center></td>
	<td style="width:350px;"><center>本文</center></td>
</tr>
<tr>
	<td style="width:100px;">
		<!--投稿日時--><center>2017-10-23 18:12:48</center>
	</td>
	<td style="width:200px;">
		@icoxfog417<br><img width="80" height="80" src="https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516">
	</td>
	<td style="width:150px;">
		<!--タグ-->
		<center><b>[Python]</b> </center>
	</td>
	<td style="width:350px;">
		<!--本文-->
		<div style="width:350px;height:150px;overflow-x:hidden;overflow-y:scroll;"><p>パフォーマンスチューニングを行う際、改修前後で効果があらわれているか確認するのは重要です。Pythonにはデフォルトで<a href="https://docs.python.jp/3/library/profile.html" rel="nofollow noopener" target="_blank">パフォーマンス解析を行うモジュールが組み込まれている</a>のですが、そのままではちょっと使いづらいく出力結果も見にくいです。そこで、簡易な記法で計測できる＋結果の可視化を行うツールを作りました。</p>

<p><a href="https://github.com/icoxfog417/pyfbi" rel="nofollow noopener" target="_blank">icoxfog417/pyfbi</a></p>

<p>まず、実行結果(<code>dump_stats</code>などで保存したファイル)を以下のようにグラフ・表で可視化できます。インストールすると<code>pyfbi_viz</code>というコマンドが使えるので、それでファイルを保存したディレクトリを指定すればOKです。改修前の計測、改修後の計測2つのファイルをフォルダに入れておけば前後の可視化が可能です。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>pyfbi_viz stat_dir=ファイルを保存したディレクトリ
</pre></div></div>

<p><a href="https://camo.qiitausercontent.com/5470419476a7ad583241b807d1f71539bccbd12c/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f33343930363663362d653433362d363435312d303532652d6637316564663366303431392e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/5470419476a7ad583241b807d1f71539bccbd12c/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f33343930363663362d653433362d363435312d303532652d6637316564663366303431392e706e67" alt="pyfbi_viz_2.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/349066c6-e436-6451-052e-f71edf3f0419.png"></a></p>

<p><a href="https://camo.qiitausercontent.com/1eaf0a293828175ff7ce7e44f0b2a231cbf0838c/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f31346666303037302d646464362d666338322d613234302d6663363962356565343036332e706e67" target="_blank" rel="nofollow noopener"><img src="https://camo.qiitausercontent.com/1eaf0a293828175ff7ce7e44f0b2a231cbf0838c/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f32353939302f31346666303037302d646464362d666338322d613234302d6663363962356565343036332e706e67" alt="pyfbi_viz_1.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/25990/14ff0070-ddd6-fc82-a240-fc69b5ee4063.png"></a></p>

<ul>
<li>
<code>pure</code>は内部で呼び出している関数の実行時間を加味しない、純粋な実行時間になります(<code>tottime</code>)。<code>total</code>は、呼び出している関数の実行時間も含めた実際の処理時間になります(<code>cumtime</code>に相当)。<code>/call</code>は呼び出し一回当たりの時間になります。</li>
</ul>

<p>計測に際しては、以下のように<code>pyfbi.target</code>を設定したところだけ計測を行うことが可能です。<code>with pyfbi.watch</code>で開始して抜けるまで観測が行われます。</p>

<div class="code-frame" data-lang="py"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pyfbi</span>


<span class="nd">@pyfbi.target</span>
<span class="k">def</span> <span class="nf">func1</span><span class="p">():</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">func2</span><span class="p">():</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>


<span class="k">with</span> <span class="n">pyfbi</span><span class="o">.</span><span class="n">watch</span><span class="p">():</span>
    <span class="p">[</span><span class="n">f</span><span class="p">()</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="p">(</span><span class="n">func1</span><span class="p">,</span> <span class="n">func2</span><span class="p">)]</span>
<span class="n">pyfbi</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># func2は計測されない</span>
<span class="n">pyfbi</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="s2">"your_stat_file_path"</span><span class="p">)</span>  <span class="c1"># ファイルに保存</span>
</pre></div></div>

<p>もちろん、特に指定せず全てを対象にすることも可能です。その場合は以下のように<code>global_watch=True</code>を設定します。</p>

<div class="code-frame" data-lang="py"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pyfbi</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">global_watch</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="p">[</span><span class="n">f</span><span class="p">()</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="p">(</span><span class="n">func1</span><span class="p">,</span> <span class="n">func2</span><span class="p">)]</span>
<span class="n">pyfbi</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># func2も計測される</span>
</pre></div></div>

<p>定期的な実行を行うことも可能です(x秒ごとに観測してファイルを保存するなど)。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre><span></span>import pyfbi

(set target to your function)

stat_dir = os.path.join(os.path.dirname(__file__), "stats")
# You can use global_watch=True if you want to profile all functions.
with pyfbi.watch_periodic(seconds=5, stat_dir=stat_dir):
    for f in [func1, func2, func2, func3, func1, func1]:
        f()
</pre></div></div>

<h2>
<span id="作成した背景" class="fragment"></span><a href="#%E4%BD%9C%E6%88%90%E3%81%97%E3%81%9F%E8%83%8C%E6%99%AF"><i class="fa fa-link"></i></a>作成した背景</h2>

<p>画像中の関数を見てピンと来た方がいるかもしれませんが、これは<a href="http://isucon.net/archives/50188676.html" rel="nofollow noopener" target="_blank">ISUCON7</a>に向けて作成されたツールです。実地でも「計測する」「改修する」「改善を確認してMergeする」というプロセスを踏んで行くのに役立ちました(実際は画像のキャッシュに気付くという壁を超えることができずその改善効果が日の目を見ることはほぼなかったのだが・・・)。</p>

<p>ベンチの値は非常に変動が大きく、またある程度待ち時間もあるため改修結果を測るのに使うのは難しかったです。その意味でも、確かな計測値が手に入るのは良かったです。</p>

<p>予選通過はならずでしたが、せっかく作ったものなのでパフォーマンス改善の折にはぜひ使っていただければと思います。</p>

<p><a href="https://github.com/icoxfog417/pyfbi" rel="nofollow noopener" target="_blank">icoxfog417/pyfbi</a><br>
(Starを頂けると予選敗退の心が癒されます m(_ _)m)</p>
</div>
	</td>
</tr>
</table>
<br />
	</body>
</html>
